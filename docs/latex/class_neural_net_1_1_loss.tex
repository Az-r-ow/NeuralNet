\doxysection{Neural\+Net\+::Loss Class Reference}
\hypertarget{class_neural_net_1_1_loss}{}\label{class_neural_net_1_1_loss}\index{NeuralNet::Loss@{NeuralNet::Loss}}
Inheritance diagram for Neural\+Net\+::Loss\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{class_neural_net_1_1_loss}
\end{center}
\end{figure}
\doxysubsubsection*{Static Public Member Functions}
\begin{DoxyCompactItemize}
\item 
static double \mbox{\hyperlink{class_neural_net_1_1_loss_a589437523689856b79dc10c1a2731573}{cmp\+Loss}} (const Eigen\+::\+Matrix\+Xd \&o, const Eigen\+::\+Matrix\+Xd \&y)
\begin{DoxyCompactList}\small\item\em This function computes the loss of the current iteration. \end{DoxyCompactList}\item 
static Eigen\+::\+Matrix\+Xd \mbox{\hyperlink{class_neural_net_1_1_loss_af37cb8add4a4b9c9948514fe825acff1}{cmp\+Loss\+Grad}} (const Eigen\+::\+Matrix\+Xd \&o, const Eigen\+::\+Matrix\+Xd \&y)
\begin{DoxyCompactList}\small\item\em This function computes the loss gradient w.\+r.\+t the outputs. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Member Function Documentation}
\Hypertarget{class_neural_net_1_1_loss_a589437523689856b79dc10c1a2731573}\label{class_neural_net_1_1_loss_a589437523689856b79dc10c1a2731573} 
\index{NeuralNet::Loss@{NeuralNet::Loss}!cmpLoss@{cmpLoss}}
\index{cmpLoss@{cmpLoss}!NeuralNet::Loss@{NeuralNet::Loss}}
\doxysubsubsection{\texorpdfstring{cmpLoss()}{cmpLoss()}}
{\footnotesize\ttfamily static double Neural\+Net\+::\+Loss\+::cmp\+Loss (\begin{DoxyParamCaption}\item[{const Eigen\+::\+Matrix\+Xd \&}]{o,  }\item[{const Eigen\+::\+Matrix\+Xd \&}]{y }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



This function computes the loss of the current iteration. 


\begin{DoxyParams}{Parameters}
{\em o} & The outputs from the output layer \\
\hline
{\em y} & The labels (the expected values)\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The loss based on the selected loss function 
\end{DoxyReturn}
\Hypertarget{class_neural_net_1_1_loss_af37cb8add4a4b9c9948514fe825acff1}\label{class_neural_net_1_1_loss_af37cb8add4a4b9c9948514fe825acff1} 
\index{NeuralNet::Loss@{NeuralNet::Loss}!cmpLossGrad@{cmpLossGrad}}
\index{cmpLossGrad@{cmpLossGrad}!NeuralNet::Loss@{NeuralNet::Loss}}
\doxysubsubsection{\texorpdfstring{cmpLossGrad()}{cmpLossGrad()}}
{\footnotesize\ttfamily static Eigen\+::\+Matrix\+Xd Neural\+Net\+::\+Loss\+::cmp\+Loss\+Grad (\begin{DoxyParamCaption}\item[{const Eigen\+::\+Matrix\+Xd \&}]{o,  }\item[{const Eigen\+::\+Matrix\+Xd \&}]{y }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [static]}}



This function computes the loss gradient w.\+r.\+t the outputs. 


\begin{DoxyParams}{Parameters}
{\em o} & The outputs from the output layer \\
\hline
{\em y} & The labels (expected vals)\\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
The current iteration\textquotesingle{}s gradient 
\end{DoxyReturn}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/\+Neural\+Net/losses/Loss.\+hpp\end{DoxyCompactItemize}
